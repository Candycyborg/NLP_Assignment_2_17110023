{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_2_classical.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbPIu-j61OEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import math\n",
        "import nltk\n",
        "import random\n",
        "from urllib.request import urlopen\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import curve_fit\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXlgc1qYYeha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_data = urlopen(\"http://www.gutenberg.org/files/31100/31100.txt\").read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTLCfdOFY04B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "string_text = str(text_data)\n",
        "start_index = string_text.find('Chapter 1')+ len('Chapter 1')\n",
        "data = string_text[start_index:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odtZhW9156az",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenizing into sentences \n",
        "sentence_list = sent_tokenize(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTKWfugaTvs-",
        "colab_type": "text"
      },
      "source": [
        "# Classical Approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygUHjIZw70hs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##removing special characters and spaces\n",
        "\n",
        "spec_chars = re.compile('[`~!@#$%^&*()+={}|\\[\\]:\";<>?,\\./“”]')\n",
        "\n",
        "for i in range(len(sentence_list)):\n",
        "    line = sentence_list[i].lower()\n",
        "    line = line.replace(\"\\\\r\",\" \")    \n",
        "    line = line.replace(\"\\\\n\",\" \")\n",
        "    line = \"<s> \" + spec_chars.sub(\"\", line) + \" </s>\"\n",
        "    sentence_list[i] = ' '.join(line.split())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfWMPkk18JXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Splitting into train and test data [4:1]\n",
        "test, train = [], []\n",
        "for i in range(len(sentence_list)):\n",
        "  train.append(sentence_list[i]) if (i%5==0) else test.append(sentence_list[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww7stwjU8gf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def n_grams(sentence_list, n):\n",
        "    dic, total = {}, 0\n",
        "    for sent in sentence_list:\n",
        "        x = sent.split()\n",
        "        for j in range(len(x)-n+1):\n",
        "            lis = []\n",
        "            for k in range(n):\n",
        "                lis.append(x[j+k])\n",
        "                s = \" \".join(lis)\n",
        "            dic[s] = dic.get(s, 0) + 1\n",
        "            total += 1\n",
        "    return dic, total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BApWQYP8Zelr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b802395-0734-428d-b185-968c3d841dbd"
      },
      "source": [
        "unigrams, total_unigrams = n_grams(train, 1)\n",
        "bigrams, total_bigrams = n_grams(train, 2)\n",
        "trigrams, total_trigrams = n_grams(train, 3)\n",
        "quadgrams, total_quadgrams = n_grams(train, 4)\n",
        "total_unigrams, total_bigrams, total_trigrams, total_quadgrams"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(164806, 158932, 153058, 147184)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r07VmxJjRH7O",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating MLE for Unigram, Bigram, Trigram, Quadgram\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG_z7m3gX1kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MLEuni = {}\n",
        "MLEbi = {}\n",
        "MLEtri = {}\n",
        "MLEquad = {}\n",
        "\n",
        "for i in unigrams.keys():\n",
        "    MLEuni[i] = unigrams[i]/total_unigrams\n",
        "    \n",
        "for i in bigrams.keys():\n",
        "        lst = i.split()\n",
        "        MLEbi[i] = bigrams[i]/unigrams[' '.join(lst[:-1])]\n",
        "      \n",
        "for i in trigrams.keys():\n",
        "        lst = i.split()\n",
        "        MLEtri[i] = trigrams[i]/bigrams[' '.join(lst[:-1])]\n",
        "      \n",
        "for i in quadgrams.keys():\n",
        "        lst = i.split()\n",
        "        MLEquad[i] = quadgrams[i]/trigrams[' '.join(lst[:-1])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxFRKPOuY-E5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse(n_grams):\n",
        "    parse_dict = {}\n",
        "    for i in n_grams.keys():\n",
        "        j = \" \".join(i.split()[:-1])\n",
        "        k = i.split()[-1]\n",
        "        \n",
        "        if (j in parse_dict):\n",
        "            parse_dict[j][0].append(k)\n",
        "            parse_dict[j][1].append(n_grams[i])\n",
        "            \n",
        "        else:\n",
        "            parse_dict[j] = [[],[]]\n",
        "            parse_dict[j][0].append(k)\n",
        "            parse_dict[j][1].append(n_grams[i])\n",
        "            \n",
        "    return parse_dict\n",
        "\n",
        "def predict_word(n, n_1_gram):\n",
        "    l = [[],[]]\n",
        "    if (n == 1):\n",
        "        l[0] = list(MLE_unigrams.keys())\n",
        "        l[1] = list(MLE_unigrams.values())\n",
        "    if (n == 2):\n",
        "        l = parse(MLEbi)[n_1_gram]\n",
        "    if (n == 3):\n",
        "        l = parse(MLEtri)[n_1_gram]\n",
        "    if (n == 4):\n",
        "        l = parse(MLEquad)[n_1_gram]\n",
        "    \n",
        "    probables, probabilities = np.array(l[0]), np.array(l[1])\n",
        "    return np.random.choice(probables, p=probabilities)\n",
        "   \n",
        "\n",
        "def helper_Generator(n, line, n_1_gram):\n",
        "    word = predict_word(n, n_1_gram)\n",
        "    \n",
        "    if (word != \"<s>\"):\n",
        "        line = line + \" \" + word\n",
        "        n_1_gram = n_1_gram.split()\n",
        "        n_1_gram.append(word)\n",
        "        n_1_gram = ' '.join(n_1_gram[1:])\n",
        "        \n",
        "    if (word == \"</s>\"):\n",
        "        return line\n",
        "      \n",
        "    else:\n",
        "        return helper_Generator(n, line, n_1_gram)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd2B3tK4Q-Fs",
        "colab_type": "text"
      },
      "source": [
        "# Generator Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scHAfzIdRA5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Generator(k):\n",
        "    line = \"<s>\"\n",
        "    \n",
        "    if (k == 3):\n",
        "        word = predict_word(2, line)\n",
        "        line = line + \" \" + word\n",
        "        if (word == \"</s>\"):\n",
        "            return line\n",
        "          \n",
        "    elif (k == 4):\n",
        "        word = predict_word(2, line)\n",
        "        line = line + \" \" + word\n",
        "        if (word == \"</s>\"):\n",
        "            return line\n",
        "          \n",
        "        word = predict_word(3, line)\n",
        "        line = line + \" \" + word\n",
        "        if (word == \"</s>\"):\n",
        "            return line\n",
        "\n",
        "    string = helper_Generator(k, line, line)\n",
        "    return string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChPMbgFhZKzB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "eb56a595-6324-4cc8-bbbb-058d4958f832"
      },
      "source": [
        "#Generate Sentences\n",
        "print(Generator(4))\n",
        "print(Generator(2))\n",
        "print(Generator(3))\n",
        "print(Generator(2))\n",
        "print(Generator(4))"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<s> elinor tried to talk of again to mrs allen that she would and the argument ended only with the young and we were a thoughtless gay set without any strict rules of conduct </s>\n",
            "<s> into the matter of jane fairfax </s>\n",
            "<s> these letters were but they always looked another way a bolt flew and she came back not to mention her solemn protestations of innocence the weakness of the matter--ha snows a little at netherfield till the marriage of her uncle and aunt had already met him at pemberley with you exactly </s>\n",
            "<s> well bred and though you so soon as for me it known </s>\n",
            "<s> from the very circumstance of its being larger sir </s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlE3D_5AQyD8",
        "colab_type": "text"
      },
      "source": [
        "# Probability Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cLg397iyObm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def EvalProb(sent, n):\n",
        "    sent,p = sent.split(),1\n",
        "    if (n == 1):\n",
        "        prob = MLEuni\n",
        "        p = -1/(prob['<s>'])\n",
        "    elif (n == 2):\n",
        "        prob = MLEbi\n",
        "    elif (n == 3):\n",
        "        prob = MLEtri\n",
        "        p *= (MLEbi.get(' '.join(sent[0:2]), 0))\n",
        "    else:\n",
        "        prob = MLEquad\n",
        "        p *= (MLEbi.get(' '.join(sent[0:2]), 0))\n",
        "        p *= (MLEtri.get(' '.join(sent[0:3]), 0))\n",
        "\n",
        "    for i in range(len(sent)-n+1):\n",
        "        n_gram = ' '.join(sent[i:i+n])\n",
        "        p *= prob.get(n_gram, 0)\n",
        "        \n",
        "    return p   \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oKAqqFjQoCB",
        "colab_type": "text"
      },
      "source": [
        "# Perplexity Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fuRsNAgI0n6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "count = n_grams(train, 3)  ##trigram\n",
        "\n",
        "def EvalPerp(sentence_list, N):\n",
        "  perp = []\n",
        "\n",
        "  for sent in test:\n",
        "      ngrams = []\n",
        "      tokens = sent.split()\n",
        "\n",
        "      for i in range(len(tokens)-N+1):\n",
        "          ngrams.append(tokens[i:i+N])\n",
        "\n",
        "      for i in ngrams:\n",
        "          seq  = ' '.join(i[:-1])\n",
        "          last = str(i[-1])\n",
        "\n",
        "          if seq not in count:\n",
        "              perp.append(1)\n",
        "\n",
        "          elif last not in count[seq]:\n",
        "              perp.append(1)\n",
        "\n",
        "          else:\n",
        "              if N!=1:\n",
        "                  x = count[seq].items()\n",
        "              else:\n",
        "                  x = count[''].items()\n",
        "              total = sum(w for c, w in x)\n",
        "              perp.append(count[seq][last]/total)\n",
        "  return perp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ7HPVFQR1iP",
        "colab_type": "text"
      },
      "source": [
        "## The generated text is human readable, but isn't grammatically perfect and hence require some cross-checking before publishing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI6UPh9pQVyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhvbgmV-SY99",
        "colab_type": "text"
      },
      "source": [
        "# Next Approach (Neural)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si92FbEMSbU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Simple RNN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfQYnAu5Sd7a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d279b317-bfd7-4d12-cc07-fa26276d8b06"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout,SimpleRNN \n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "import keras.utils as utils\n",
        "import re\n",
        "from keras.callbacks import ModelCheckpoint\n"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHL3OoKWSt-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Check File Assignment_Nueral_2.ipynb for remaining approaches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PN_T2ttsTIDS",
        "colab_type": "text"
      },
      "source": [
        "### Even in the nueral approach we might see grammatically incorrect sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhZ7Dz19TQWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}